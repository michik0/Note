# 1. 什么是消息队列？

你可以把消息队列理解为一个使用队列来通信的组件。它的本质，就是个转发器，包含发消息、存消息、消费消息的过程。最简单的消息队列模型如下：

![image.png](https://raw.githubusercontent.com/michik0/notes-image/master/20230430112232.png)

我们通常说的消息队列，简称 MQ（Message Queue），它其实就指消息 中间件，当前业界比较流行的开源消息中间件包括： RabbitMQ、RocketMQ、Kafka。

# 2. 消息队列有哪些使用场景

1. 应用解耦
2. 流量削峰
3. 异步处理
4. 消息通讯
5. 远程调用

## 2.1 应用解耦

举个常见业务场景：下单扣库存，用户下单后，订单系统去通知库存系统扣减。

传统的做法就是订单系统直接调用库存系统：

![image.png](https://raw.githubusercontent.com/michik0/notes-image/master/20230430112421.png)

- 如果库存系统无法访问，下单就会失败，订单和库存系统存在耦合关系。
- 如果业务又接入一个营销积分服务，那订单下游系统要扩充，如果未来接入越来越多的下游系统，那订单系统代码需要**经常修改**。

**如何解决这个问题呢？** 可以引入消息队列

1. 订单系统：用户下单后，消息写入到消息队列，返回下单成功。
2. 库存系统：订阅下单消息，获取下单信息，进行库存操作。

![image.png](https://raw.githubusercontent.com/michik0/notes-image/master/20230430112630.png)

## 2.2 流量削峰

流量削峰也是消息队列的**常用场景**。我们做秒杀实现的时候，需要避免流量暴涨，打垮应用系统的风险。可以在应用前面加入消息队列。

![image.png](https://raw.githubusercontent.com/michik0/notes-image/master/20230430113006.png)

假设秒杀系统每秒最多可以处理 2k 个请求，每秒却有 5k 的请求过来，可以引 入消息队列，秒杀系统每秒从消息队列拉 2k 请求处理得了。 有些伙伴担心这样会出现**消息积压**的问题，

- 首先秒杀活动不会每时每刻都那么多请求过来，高峰期过去后，积压的请求可以慢慢处理；
- 其次，如果消息队列长度超过最大数量，可以直接抛弃用户请求或跳转到错误页面；

## 2.3 异步处理

我们经常会遇到这样的业务场景：用户注册成功后，给它发个短信和发个邮件。

如果注册信息入库是 30ms，发短信、邮件也是 30ms，三个动作串行执行的话，会比较耗时，响应 90ms：

![image.png](https://raw.githubusercontent.com/michik0/notes-image/master/20230430113333.png)

如果采用并行执行的方式，可以减少响应时间。注册信息入库后，同时异步发 短信和邮件。如何实现异步呢，用消息队列即可，就是说，注册信息入库成功 后，写入到消息队列（这个一般比较快，如只需要 3ms），然后异步读取发邮件和短信。

![image.png](https://raw.githubusercontent.com/michik0/notes-image/master/20230430113402.png)

# 3. 消息队列如何解决消息丢失问题？

一个消息从生产者产生，到被消费者消费，主要经过这 3 个过程：

![image.png](https://raw.githubusercontent.com/michik0/notes-image/master/20230511210616.png)

因此如何保证 MQ 不丢失消息，可以从这三个阶段阐述：

- 生产者保证不丢消息
- 存储端不丢消息
- 消费者不丢消息

## 生产者保证不丢消息

生产端如何保证不丢消息呢？

确保生产的消息能到达存储端。 

如果是 RocketMQ 消息中间件，Producer 生产者提供了三种发送消息的方式，分别是：

- 同步发送
- 异步发送
- 单向发送

生产者要想发消息时保证消息不丢失，可以：

- 采用同步方式发送，send 消息方法返回成功状态，就表示消息正常到达了存储端 Broker。
- 如果 send 消息异常或者返回非成功状态，可以重试。
- 可以使用事务消息，RocketMQ 的事务消息机制就是为了保证零丢失来设计的。

## 存储端不丢消息

如何保证存储端的消息不丢失呢？ 确保消息持久化到磁盘。

刷盘机制分**同步刷盘**和**异步刷盘**：

- **同步刷盘**：生产者消息发过来时，只有持久化到磁盘，RocketMQ 的存储端 Broker 才返回一个成功的 ACK 响应，这就是同步刷盘。它保证消息不丢失，但是影响了性能。 
- **异步刷盘**：只要消息写入 PageCache 缓存，就返回一个成功的 ACK 响应。 这样提高了 MQ 的性能，但是如果这时候机器断电了，就会丢失消息。

Broker 一般是**集群部署**的，有 master 主节点和 slave 从节点。消息到 Broker 存储端，只有主节点和从节点都写入成功，才反馈成功的 ack 给生产者。这就是**同步复制**，它保证了消息不丢失，但是降低了系统的吞吐量。与之对应的就是**异步复制**，只要消息写入主节点成功，就返回成功的 ack，它速度快，但是会有性能问题。

## 消费阶段不丢消息

消费者执行完业务逻辑，再反馈会 Broker 说消费成功，这样才可以保证消费 阶段不丢消息。

# 4. 消息队列如何保证消息的顺序性

消息的有序性，就是指可以按照消息的发送顺序来消费。有些业务对消息的顺序是有要求的，比如**先下单再付款，最后再完成订单**，这样等。假设生产者先后产生了两条消息，分别是下单消息（M1），付款消息（M2），M1 比 M2 先产生，**如何保证 M1 比 M2 先被消费呢？**

![image.png](https://raw.githubusercontent.com/michik0/notes-image/master/20230511211924.png)

为了保证消息的顺序性，可以将将 M1、M2 发送到同一个 Server 上，当 M1 发送完收到 ack 后，M2 再发送。如图：

![image.png](https://raw.githubusercontent.com/michik0/notes-image/master/20230511211939.png)

这样还是可能会有问题，因为从 MQ 服务器到服务端，**可能存在网络延迟**，虽然 M1 先发送，但是它比 M2 晚到。

![image.png](https://raw.githubusercontent.com/michik0/notes-image/master/20230511212011.png)

那还能怎么办才能保证消息的顺序性呢？将 M1 和 M2 发往同一个消费者，且发送 M1 后，等到消费端 ACK 成功后，才发送 M2 就得了。

![image.png](https://raw.githubusercontent.com/michik0/notes-image/master/20230511212601.png)

# 5. 消息队列有可能发生重复消费，如何避免，如何做到幂等？

消息队列是可能发生重复消费的。

- 生产端：为了保证消息的可靠性，它可能往 MQ 服务器重复发送消息，直到拿到成功的 ACK。 
- 消费端：消费端消费消息一般是这个流程：拉取消息、业务逻辑处理、 提交消费位移。假设业务逻辑处理完，事务提交了，但是需要更新消费位移时，消费者挂了，这时候另一个消费者就会拉到重复消息了。

**如何幂等处理重复消息呢？**

幂等处理重复消息，简单来说，就是搞个本地表，带唯一业务标记的，利用主键或者唯一性索引，每次处理业务，先校验一下就好啦。又或者用 redis 缓存下业务标记，每次看下是否处理过了。

# 6. 如何处理消息队列的消息积压问题

消息积压是因为生产者的生产速度，大于消费者的消费速度。遇到消息积压问题时，我们需要先排查，是不是有 bug 产生了。 

- 如果不是 bug，我们可以优化一下消费的逻辑，比如之前是一条一条消息消费处理的话，我们可以确认是不是可以优为批量处理消息。如果还是慢，我们可以考虑水平扩容，增加 Topic 的队列数，和消费组机器的数量，提升整体消费能力。

- 如果是 bug 导致几百万消息持续积压几小时。有如何处理呢？ 需要解决 bug，**临时紧急扩容**，大概思路如下：
	- 先修复 consumer 消费者的问题，以确保其恢复消费速度，然后将现有 consumer 都停掉。
	- 新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。
	- 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue。
	- 接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 qeue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资 源扩大 10 倍，以正常的 10 倍速度来消费数据。
	- 等快速消费完积压数据之后，得恢复原先部署的架构，重新用原先的 consumer 机器来消费消息。

# 7. 消息队列技术选型，Kafka 还是 RocketMQ，还是 RabbitMQ

|            | Kafka                                                             | RocketMQ                                                            | RabbitMQ                                               |
| ---------- | ----------------------------------------------------------------- | ------------------------------------------------------------------- | ------------------------------------------------------ |
| 单机吞吐量 | 17.3w/s                                                           | 11.6w/s                                                             | 2.6w/s （ 消息做持久化）                               |
| 开发语言   | Scala/Java                                                        | Java                                                                | Erlang                                                 |
| 主要维护者 | Apache                                                            | Alibaba                                                             | Mozilla/Spring                                         |
| 订阅形式   | 基于 topic，按照 topic 进行正则匹配的发布订阅模式                 | 基于 topic/messageTag，按照消息类型、属性进行正则匹配的发布订阅模式 | 提供了4种：direct、topic、Headers、fanout              |
| 持久化     | 支持大量堆积                                                      | 支持大量堆积                                                        | 支持少量堆积                                           |
| 顺序消息   | 支持                                                              | 支持                                                                | 不支持                                                 |
| 集群方式   | 天然的 LeaderSlave，无状态集群，每台服务器既 是 Master 也是 Slave | 常用多对 `Master-Slave` 模式，开源版本需手动切换 Slave 变成 Master  | 支持 `简单集群`，`复制` 模式，对高级集群模式支持不好。 |
| 性能稳定性 | 较差                                                              | 一般                                                                | 好                                                       |

RabbitMQ 是开源的，比较稳定的支持，活跃度也高，但是不是 Java 语言开发的。 很多公司用 RocketMQ，是阿里出品的。 如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的。

# 8. 消息中间件如何做到高可用

以 Kafka 为例

Kafka 的基础集群架构，由多个 broker 组成，每个 broker 都是一个节点。当你创建一个 topic 时，它可以划分为多个 partition，而每个 partition 放一部分数据，分别存在于不同的 broker 上。也就是说，一个 topic 的数据，是分散放在多个机器上的，每个机器就放一部分数据。 有些伙伴可能有疑问，每个 partition 放一部分数据，如果对应的 broker 挂了， 那这部分数据是不是就丢失了？那还谈什么高可用呢？

Kafka 0.8 之后，提供了复制品副本机制来保证高可用，即每个 partition 的数据都会同步到其它机器上，形成多个副本。然后所有的副本会选举一个 leader 出来，让 leader 去跟生产和消费者打交道，其他副本都是 follower。 写数据时，leader 负责把数据同步给所有的 follower，读消息时， 直接读 leader 上的数据即可。如何保证高可用的？就是假设某个 broker 宕机，这个 broker 上的 partition 在其他机器上都有副本的。如果挂的是 leader 的 broker 呢？其他 follower 会重新选一个 leader 出来。

# 9. 如何保证数据一致性，事务消息如何实现

一条普通的 MQ 消息，从产生到被消费，大概流程如下：

![image.png](https://raw.githubusercontent.com/michik0/notes-image/master/20230515215157.png)

1. 生产者产生消息，发送带 MQ 服务器
2. MQ 收到消息后，将消息持久化到存储系统。
3. MQ 服务器返回 ACk 到生产者。
4. MQ 服务器把消息 push 给消费者
5. 消费者消费完消息，响应 ACK
6. MQ 服务器收到 ACK，认为消息消费成功，即在存储中删除消息。

**消息队列的事务消息流程是怎样的呢？**

![image.png](https://raw.githubusercontent.com/michik0/notes-image/master/20230515215304.png)

1. 生产者产生消息，发送一条半事务消息到 MQ 服务器
2. MQ 收到消息后，将消息持久化到存储系统，这条消息的状态是待发送状态。
3. MQ 服务器返回 ACK 确认到生产者，此时 MQ 不会触发消息推送事件
4. 生产者执行本地事务
5. 如果本地事务执行成功，即 commit 执行结果到 MQ 服务器；如果执行失败，发 送 rollback。
6. 如果是正常的 commit，MQ 服务器更新消息状态为可发送；如果是 rollback，即删除消息。
7. 如果消息状态更新为可发送，则 MQ 服务器会 push 消息给消费者。消费者消费完就回 ACK。
8. 如果 MQ 服务器长时间没有收到生产者的 commit 或者 rollback，它会反查生产者，然后根据查询到的结果执行最终状态。

我们举个下订单清空购物车的例子吧。订单系统创建完订单后，然后发消息给 下游系统购物车系统，清空购物车。

1. 生产者（订单系统）产生消息，发送一条半事务消息到 MQ 服务器
2. MQ 收到消息后，将消息持久化到存储系统，这条消息的状态是待发送状态。
3. MQ 服务器返回 ACK 确认到生产者，此时 MQ 不会触发消息推送事件
4. 生产者执行本地事务（订单创建成功，提交事务消息）
5. 如果本地事务执行成功，即 commit 执行结果到 MQ 服务器；如果执行失败，发 送 rollback。
6. 如果是 commit 正常提交，MQ 服务器更新消息状态为可发送；如果是 rollback，即删除消息。
7. 如果消息状态更新为可发送，则 MQ 服务器会 push 消息给消费者（购物车系统）。 消费者消费完（即拿到订单消息，清空购物车成功）就应答 ACK。
8. 如果 MQ 服务器长时间没有收到生产者的 commit 或者 rollback，它会反查生产 者，然后根据查询到的结果（回滚操作或者重新发送消息）执行最终状态。

**如果消费者消费失败怎么办呢？那数据是不是不一致啦？** 

所以就需要消费者消费成功，执行业务逻辑成功，再反馈 ack 嘛。如果消费者 消费失败，那就自动重试嘛，接口支持幂等即可。