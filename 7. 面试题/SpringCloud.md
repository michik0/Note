# 1. SOA、分布式、微服务有什么关系和区别？

1. 分布式架构是指将单体架构中的各个部分拆分，然后部署不同的机器或进程中去，SOA和微服务基本上都是分布式架构。
2. SOA是一种面向服务的架构，系统的所有服务都注册在总线上，当调用服务时，从总线上查找服务信息，然后调用。
3. 微服务是一种更彻底的面向服务的架构，将系统中各个功能个体抽成一个个小的应用程序，基本保持一个应用对应的一个服务的架构。

# 2. SpringCloud 核心组件及其作用

![image.png](https://raw.githubusercontent.com/michik0/notes-image/master/20230602141526.png)
**Eureka：服务注册与发现**

>注册

每个服务都向Eureka登记自己提供服务的元数据，包括服务的ip地址、端口号、版本号、通信协议等。

Eureka将各个服务维护在了一个服务清单中(双层Map，第一层key是服务名，第二层key是实例名，value是服务地址加端口)。同时对服务维持心跳，剔除不可用的服务，Eureka集群各节点相互注册每个实例中都有一样的服务清单。

>发现

Eureka注册的服务之间调用不需要指定服务地址，而是通过服务名向注册中心咨询，并获取所有服务实例清单(缓存到本地)，然后实现服务的请求访问。

**Ribbon：**

服务间发起请求的时候，基于Ribbon做负载均衡，从一个服务的多台机器中选择一台(被调用方的服务地址有多个)， Ribbon也是通过发起http请求，来进行的调用，只不过是通过调用服务名的地址来实现的。虽然说Ribbon不用去具体请求服务实例的ip地址或域名了，但是每调用一个接口都还要手动去发起Http请求

```java
@Restcontroller
public class Consumercontroller {
	@Autowired
	RestTemplate restTemplate;
	
	@GetMapping("/ribbon-consumer")
	public String helloConsumer){
		return
restTemplate.getForEntity("http://exampleservice/index",string.class).getBody();
}
```

**Feign：**

基于Feign的动态代理机制，根据注解和选择的机器，拼接请求URL地址，发起请求，简化服务间的调用，在Ribbon的基础上进行了进一步的封装。单独抽出了一个组件，就是Spring Cloud Feign。在引入SpringCloud Feign后，我们只需要创建一个接口并用注解的方式来配置它，即可完成对服务提供方的接口绑定。

调用远程就像调用本地服务一样

```java
@RestController
public class TestController{
	@Resource
	UserClient userClient;
	
	@RequestMapping("/test") 
	public String test() {
		String userClient.getuser(); 
		return user;
	}
}

@Feignclient(name = "user") 
public interface UserClient {
	@GetMapping("/getuser") 
	String getUser();
}

```

**Hystrix：**

发起请求是通过Hystrixl的线程池来走的，不同的服务走不同的线程池，实现了不同服务调用的隔离，通过统计接口超时次数返回默认值，实现服务熔断和降级。

**Zuul：**

如果前端、移动端要调用后端系统，统一从Zuul网关进入，由Zuul网关转发请求给对应的服务，通过与Eureka进行整合，将自身注册为Eureka下的应用，从Eureka下获取所有服务的实例，来进行服务的路由。Zuul还提供了一套过滤器机制，开发者可以自己指定哪些规队则的请求需要执行校验逻辑，只有通过校验逻辑的请求才会被路由到具体服务实例上，否则返回错误提示。

# 3. Spring Cloud 和 Dubbo 有哪些区别？

Spring Cloud是一个微服务框架，提供了微服务领域中的很多功能组件，Dubbo一开始是一个RPC调用框架，核心是解决服务调用间的问题，Spring Cloud是一个大而全的框架，Dubbo则更侧重于服务调用，所以Dubbo所提供的功能没有Spring Cloud全面，但是Dubbol的服务调用性能比Spring Cloudi高，不过Spring Cloud和Dubbo并不是对立的，是可以结合起来一起使用的。

# 4. 什么是服务熔断？什么是服务降级？区别是什么？

**服务熔断：**

当服务A调用的某个服务B接口不可用时，上游服务A收到了大量的请求，A服务为了保证自己不受影响，从而不再调用服务B，直接返回一个结果，减轻服务A和服务B的压力，直到服务B恢复。

**服务降级：**

当发现系统压力过载时，可以通过关闭某个服务，或限流某个服务来减轻系统压力，这就是服务降级。

比如说618期间如果服务器压力过大，关闭商品的评论功能

>相同点：

1. 都是为了防止系统崩溃
2. 都让用户体验到某些功能暂时不可用

>不同点：

- 熔断是下游服务故障触发的
- 降级是为了降低系统负载

# 5. 高并发场景下如何实现系统限流

限流一般需要结合容量规划和压测来进行。当外部请求接近或者达到系统的最大阈值时，触发限流，采取其他的手段进行降级，保护系统不被压垮。常见的降级策略包括延迟处理、拒绝服务、随机拒绝等。

**方法一：计数器法**

1. 将时间划分为固定的窗口大小，例如1s
2. 在窗口时间段内，每来一个请求，对计数器加1。
3. 当计数器达到设定限制后，该窗口时间内的之后的请求都被丢弃处理。
4. 该窗口时间结束后，计数器清零，从新开始计数。

>缺点

有可能前900ms只有1个请求，后面100ms进来90个请求，会可能导致服务器挂掉。

**方法二：滑动窗口计数法**

1. 将时间划分为细粒度的区间，每个区间维持一个计数器，每进入一个请求则将计数器加一。
2. 多个区间组成一个时间窗口，每流逝一个区间时间后，则抛弃最老的一个区间，纳入新区间。
3. 若当前窗口的区间计数器总和超过设定的限制数量，则本窗口内的后续请求都被丢弃。

**方法三：漏桶算法**

如果外部请求超出当前阈值，则会在容易里积蓄，一直到溢出，系统并不关心溢出的流量。从出口处限制请求速率，并不存在计数器法的临界问题，请求曲线始终是平滑的。无法应对突发流量，相当于一个空桶+固定处理线程（例如只有3个线程处理请求，多出来的不够处理的请求不予处理）

**方法四：令牌桶算法**

假设一个大小恒定的桶，这个桶的容量和设定的阈值有关，桶里放着很多令牌，通过一个固定的速率，往里边放入令牌，如果桶满了，就把令牌丢掉，最后桶中可以保存的最大令牌数永远不会超过桶的大小。当有请求进入时，就尝试从桶里取走一个令牌，如果桶里是空的，那么这个请求就会被拒绝。

>漏桶算法保护了下游系统，而令牌桶算法只保护了本系统

# 6. Spring Cloud 各个组件的功能

1. Eureka：注册中心，用来进行服务的自动注册和发现
2. Ribbon：负载均衡组件，用来在消费者调用服务时进行负载均衡
3. Feign：基于接口的申明式的服务调用客户端，让调用变得更简单
4. Hystrix：断路器，负责服务容错
5. Zuu：服务网关，可以进行服务路由、服务降级、负载均衡等
6. Nacos：分布式配置中心以及注册中心
7. Spring Cloud Config：分布式配置中心
8. Spring Cloud Bus：消息总线

# 7. 什么是服务雪崩？什么是服务限流？

1. 当服务A调用服务B，服务B调用C，此时大量请求突然请求服务A，假如服务A本身能抗住这些请求，但是如果服务C抗不住，导致服务C请求堆积，从而服务B请求堆积，从而服务A不可用，这就是服务雪崩，**解决方式就是服务降级和服务熔断。**

2. 服务限流是指在高并发请求下，为了保护系统，可以对访问服务的清求进行数量上的限制，从而防止系统不被大量请求压垮，在秒杀中，限流是非常重要的。

# 8. 介绍下 Nacos 注册中心的核心功能？

**服务注册：**

当服务启动时，通过 REST 请求的方式向 NACOS Server 注册自己的服务

**服务心跳：**

Nacos Client 会维护一个定时心跳持续通知 Nacos Server，默认5s一次，如果 Nacos 超过了15秒没有接收到心跳，会将服务健康状态设置为 false，如果 Nacos Client 超过了30秒没有接收到心跳剔除服务。

**服务发现：**

Nacos Client 会有一个定时任务，实时去 Nacos Server 拉取健康服务

**服务停止：**

Nacos Client 会主动通过 REST 请求 Nacos Server 发送一个注销的请求

![image.png](https://raw.githubusercontent.com/michik0/notes-image/master/20230604093531.png)

# 9. 谈谈 Nacos 配置中心

配置中心集中管理服务的配置，提高维护性，时效性，安全性

**哪些东西可以作为配置？**

比方说，数据库连接Url，缓存连接url字符串，数据库的用户名，密码都可以作为配置的字符串，除此之外，还有一些可以动态调整的参数，比方说，客户端的超时设置限流规则和降级开关，流量的动态调度，比方说某个功能只是针对某个地区用户，还有某个功能只在大促的时段开放，如果这种需要通过静态的方式去配置或者发布的方式去配置，那么响应速度是非常慢，可能对业务存在风险，如果有一套集中式的配置中心，只需要相关人员在配置中心动态去调整参数，就基本上可以实时或准实时去调整相关对应的业务。所以配置中心在微服务中算是一个举足轻重的组件。

**服务端推送配置还是客户端自己拉取配置？**

现在我们了解了 Nacos 的配置管理的功能了，但是有一个问题我们需要弄明白，那就是 Nacos 客户端是怎么实时获取到Nacos服务端的最新数据的。

其实客户端和服务端之间的数据交互，无外乎两种情况：
- 服务端推数据给客户端
- 客户端从服务端拉数据

那到底是推还是拉呢，从Nacos客户端通过Listener来接收最新数据进行分析

![image.png](https://raw.githubusercontent.com/michik0/notes-image/master/20230604094410.png)

Nacos 服务端创建了相关的配置项后，客户端就可以进行监听了。

客户端是通过一个定时任务来检查自己监听的配置项的数据的，一旦服务端的数据发生变化时，客户端将会获取到最新的数据，并将最新的数据保存在一个 CacheData 对象中，然后会重新计算CacheData的md5属性的值，此时就会对该 CacheData 所绑定的 Listener 触发 receiveConfigInfo(接收配置信息)回调。

**客户端向服务端拉取数据的优势**

如果用推的方式，服务端需要维持与客户端的长连接，这样的话需要耗费大量的资源，并且还需要考虑连接的有效性，例如需要通过心跳来维持两者之间的连接。而用拉的方式，客户端只需要通过一个无状态的htp请求即可获取到服务端的数据。

# 10. 服务网关可以做什么？

面对互联网复杂的业务系统，基本可以将服务网关分成两类：流量网关和业务网关

**流量网关：**


跟具体的后端业务系统和服务完全无关的部分，比如安全策略、全局性流控策略、流量分发策略等。

具体应用：全局性流控日志统计、防止SQL注入、防止Web攻击屏蔽工具扫描、黑白IP名单、证书/加解密处理

**业务网关：** 

针对具体的后端业务系统，或者是服务和业务有一定关联性的部分，并且一般被直接部署在业务服务的前面。业务网关一般部署在流量网关之后，业务系统之前，比流量网关更靠近系统。我们大部分情况下说的API网关，狭义上指的是业务网关。并且如果系统的规模不大，我们也会将两者合二为一，使用一个网关来处理所有的工作

具体应用：服务级别流控，服务降级与熔断，路由与负载均衡、灰度策略，服务过滤，聚合与发现，权限验证与用户等级策略，业务规则与参数校验，多级缓存策略